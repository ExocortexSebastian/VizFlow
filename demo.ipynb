{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# VizFlow Demo - Basic Usage\n\n**Version**: 0.4.0  \n**Repository**: [github.com/ExocortexSebastian/VizFlow](https://github.com/ExocortexSebastian/VizFlow)\n\nThis notebook demonstrates the current features of VizFlow for analyzing TB-scale financial market data.\n\n---\n\n## ğŸ“¦ What's Available (v0.4.0)\n\nâœ… **Config & Market** - Global configuration with CN/CRYPTO market presets  \nâœ… **Time Operations** - Parse timestamps with market session awareness  \nâœ… **Binning** - Discretize continuous values for aggregation  \nâœ… **Aggregation** - Group and compute metrics with Polars expressions  \n\n## ğŸš€ Coming Soon\n\nâ³ **v0.5.0** - Enrichment + FIFO matching (trade lifecycle analysis)  \nâ³ **v0.6.0** - Forward returns + trading calendar  \nâ³ **v0.7.0** - Execution framework (run_batch, run_cluster)  \nâ³ **v0.8.0** - Visualization (Dash dashboards)\n\nSee [docs/VERSIONING.md](https://github.com/ExocortexSebastian/VizFlow/blob/main/docs/VERSIONING.md) for full roadmap.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import VizFlow and Polars, then configure the global settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import vizflow as vf\n",
    "\n",
    "# Configure VizFlow once at the top of your notebook\n",
    "config = vf.Config(\n",
    "    market=\"CN\",\n",
    "    input_dir=\"data/raw\",\n",
    "    output_dir=\"data/processed\",\n",
    "    columns={\n",
    "        \"timestamp\": \"ticktime\",\n",
    "        \"price\": \"close\",\n",
    "        \"volume\": \"vol\",\n",
    "        \"symbol\": \"ukey\"\n",
    "    },\n",
    "    binwidths={\n",
    "        \"alpha\": 1e-4,\n",
    "        \"return\": 1e-4\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set global config - now all VizFlow functions will use these settings\n",
    "vf.set_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data\n",
    "\n",
    "Create sample tick data for demonstration. In production, you'd use:\n",
    "```python\n",
    "df = pl.scan_parquet(\"data/raw/20241201.parquet\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data loaded (LazyFrame - not yet computed)\n"
     ]
    }
   ],
   "source": [
    "# Sample tick data - CN market trading hours\n",
    "df = pl.DataFrame({\n",
    "    \"ukey\": [\"600000\", \"600000\", \"600000\", \"000001\", \"000001\", \"000001\"],\n",
    "    \"ticktime\": [\n",
    "        93000000,  # 09:30:00.000 (market open)\n",
    "        93012145,  # 09:30:12.145\n",
    "        100000000, # 10:00:00.000\n",
    "        130000000, # 13:00:00.000 (afternoon open)\n",
    "        142058425, # 14:20:58.425\n",
    "        150000000  # 15:00:00.000 (market close)\n",
    "    ],\n",
    "    \"close\": [10.52, 10.53, 10.51, 15.82, 15.85, 15.83],\n",
    "    \"vol\": [1000, 1500, 2000, 3000, 2500, 1800],\n",
    "    \"alpha\": [0.00012, 0.00025, -0.00018, 0.00032, 0.00015, -0.00008]\n",
    "}).lazy()\n",
    "\n",
    "print(\"Sample data loaded (LazyFrame - not yet computed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Timestamps\n",
    "\n",
    "Convert integer timestamps (HHMMSSMMM format) to:\n",
    "- **tod_ticktime**: Time of day (pl.Time) - perfect for plotting\n",
    "- **elapsed_ticktime**: Milliseconds since market open (pl.Int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timestamp columns added:\n",
      "shape: (6, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ ticktime  â”† tod_ticktime â”† elapsed_ticktime â”‚\n",
      "â”‚ ---       â”† ---          â”† ---              â”‚\n",
      "â”‚ i64       â”† time         â”† i64              â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 93000000  â”† 09:30:00     â”† 0                â”‚\n",
      "â”‚ 93012145  â”† 09:30:12.145 â”† 12145            â”‚\n",
      "â”‚ 100000000 â”† 10:00:00     â”† 1800000          â”‚\n",
      "â”‚ 130000000 â”† 13:00:00     â”† 7200000          â”‚\n",
      "â”‚ 142058425 â”† 14:20:58.425 â”† 12058425         â”‚\n",
      "â”‚ 150000000 â”† 15:00:00     â”† 14400000         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Parse timestamps - no need to pass market parameter!\n",
    "df = vf.parse_time(df, timestamp_col=\"ticktime\")\n",
    "\n",
    "# Collect and display\n",
    "result = df.collect()\n",
    "print(\"\\nTimestamp columns added:\")\n",
    "print(result.select([\"ticktime\", \"tod_ticktime\", \"elapsed_ticktime\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observations:**\n",
    "- Morning session: 09:30:00 â†’ elapsed = 0 ms\n",
    "- Afternoon session: 13:00:00 â†’ elapsed = 7,200,000 ms (2 hours of morning)\n",
    "- `tod_ticktime` is pl.Time - can be used directly in plots as x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discretize Values (Binning)\n",
    "\n",
    "Round values to bins for aggregation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha values binned:\n",
      "shape: (6, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ ukey   â”† alpha    â”† alpha_bin â”† tod_ticktime â”‚\n",
      "â”‚ ---    â”† ---      â”† ---       â”† ---          â”‚\n",
      "â”‚ str    â”† f64      â”† i64       â”† time         â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 600000 â”† 0.00012  â”† 1         â”† 09:30:00     â”‚\n",
      "â”‚ 600000 â”† 0.00025  â”† 2         â”† 09:30:12.145 â”‚\n",
      "â”‚ 600000 â”† -0.00018 â”† -2        â”† 10:00:00     â”‚\n",
      "â”‚ 000001 â”† 0.00032  â”† 3         â”† 13:00:00     â”‚\n",
      "â”‚ 000001 â”† 0.00015  â”† 1         â”† 14:20:58.425 â”‚\n",
      "â”‚ 000001 â”† -0.00008 â”† -1        â”† 15:00:00     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Bin alpha values to 0.0001 increments\n",
    "df = vf.bin(df, widths={\"alpha\": 1e-4})\n",
    "\n",
    "result = df.collect()\n",
    "print(\"\\nAlpha values binned:\")\n",
    "print(result.select([\"ukey\", \"alpha\", \"alpha_bin\", \"tod_ticktime\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning logic:**\n",
    "- `alpha_bin = round(alpha / binwidth)`\n",
    "- Example: alpha=0.00012 â†’ bin=1 (because 0.00012/0.0001 â‰ˆ 1.2 rounds to 1)\n",
    "- Useful for grouping similar values together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aggregate Data\n",
    "\n",
    "Group by bins and calculate metrics using Polars expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated results:\n",
      "shape: (6, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ ukey   â”† alpha_bin â”† count â”† total_volume â”† avg_price â”† vwap  â”‚\n",
      "â”‚ ---    â”† ---       â”† ---   â”† ---          â”† ---       â”† ---   â”‚\n",
      "â”‚ str    â”† i64       â”† u32   â”† i64          â”† f64       â”† f64   â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 000001 â”† -1        â”† 1     â”† 1800         â”† 15.83     â”† 15.83 â”‚\n",
      "â”‚ 000001 â”† 1         â”† 1     â”† 2500         â”† 15.85     â”† 15.85 â”‚\n",
      "â”‚ 000001 â”† 3         â”† 1     â”† 3000         â”† 15.82     â”† 15.82 â”‚\n",
      "â”‚ 600000 â”† -2        â”† 1     â”† 2000         â”† 10.51     â”† 10.51 â”‚\n",
      "â”‚ 600000 â”† 1         â”† 1     â”† 1000         â”† 10.52     â”† 10.52 â”‚\n",
      "â”‚ 600000 â”† 2         â”† 1     â”† 1500         â”† 10.53     â”† 10.53 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Define aggregation metrics\n",
    "metrics = {\n",
    "    \"count\": pl.len(),\n",
    "    \"total_volume\": pl.col(\"vol\").sum(),\n",
    "    \"avg_price\": pl.col(\"close\").mean(),\n",
    "    \"vwap\": (pl.col(\"close\") * pl.col(\"vol\")).sum() / pl.col(\"vol\").sum()\n",
    "}\n",
    "\n",
    "# Aggregate by symbol and alpha bin\n",
    "agg_df = vf.aggregate(\n",
    "    df,\n",
    "    group_by=[\"ukey\", \"alpha_bin\"],\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "result = agg_df.collect().sort([\"ukey\", \"alpha_bin\"])\n",
    "print(\"\\nAggregated results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Workflow Example\n",
    "\n",
    "Putting it all together in a typical analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>alpha_bin</th><th>count</th><th>avg_price</th><th>total_volume</th></tr><tr><td>i64</td><td>u32</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>-15</td><td>2</td><td>10.5</td><td>3000</td></tr><tr><td>-14</td><td>2</td><td>10.51</td><td>3200</td></tr><tr><td>-13</td><td>2</td><td>10.52</td><td>3400</td></tr><tr><td>-12</td><td>2</td><td>10.53</td><td>3600</td></tr><tr><td>-11</td><td>2</td><td>10.54</td><td>3800</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10</td><td>2</td><td>10.55</td><td>4000</td></tr><tr><td>11</td><td>2</td><td>10.56</td><td>4200</td></tr><tr><td>12</td><td>2</td><td>10.57</td><td>4400</td></tr><tr><td>13</td><td>2</td><td>10.58</td><td>4600</td></tr><tr><td>14</td><td>2</td><td>10.59</td><td>4800</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (30, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ alpha_bin â”† count â”† avg_price â”† total_volume â”‚\n",
       "â”‚ ---       â”† ---   â”† ---       â”† ---          â”‚\n",
       "â”‚ i64       â”† u32   â”† f64       â”† i64          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ -15       â”† 2     â”† 10.5      â”† 3000         â”‚\n",
       "â”‚ -14       â”† 2     â”† 10.51     â”† 3200         â”‚\n",
       "â”‚ -13       â”† 2     â”† 10.52     â”† 3400         â”‚\n",
       "â”‚ -12       â”† 2     â”† 10.53     â”† 3600         â”‚\n",
       "â”‚ -11       â”† 2     â”† 10.54     â”† 3800         â”‚\n",
       "â”‚ â€¦         â”† â€¦     â”† â€¦         â”† â€¦            â”‚\n",
       "â”‚ 10        â”† 2     â”† 10.55     â”† 4000         â”‚\n",
       "â”‚ 11        â”† 2     â”† 10.56     â”† 4200         â”‚\n",
       "â”‚ 12        â”† 2     â”† 10.57     â”† 4400         â”‚\n",
       "â”‚ 13        â”† 2     â”† 10.58     â”† 4600         â”‚\n",
       "â”‚ 14        â”† 2     â”† 10.59     â”† 4800         â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typical workflow: Load â†’ Parse â†’ Filter â†’ Bin â†’ Aggregate\n",
    "(\n",
    "    pl.DataFrame({\n",
    "        \"ukey\": [\"600000\"] * 100,\n",
    "        \"ticktime\": [93000000 + i*1000 for i in range(100)],  # Every second for 100 seconds\n",
    "        \"close\": [10.50 + (i % 10) * 0.01 for i in range(100)],\n",
    "        \"vol\": [1000 + (i % 20) * 100 for i in range(100)],\n",
    "        \"alpha\": [(i % 30 - 15) * 0.00001 for i in range(100)]\n",
    "    }).lazy()\n",
    "    # Parse timestamps\n",
    "    .pipe(vf.parse_time, timestamp_col=\"ticktime\")\n",
    "    # Filter to first minute only\n",
    "    .filter(pl.col(\"elapsed_ticktime\") < 60000)\n",
    "    # Bin alpha\n",
    "    .pipe(vf.bin, widths={\"alpha\": 1e-5})\n",
    "    # Aggregate\n",
    "    .pipe(vf.aggregate, \n",
    "          group_by=[\"alpha_bin\"], \n",
    "          metrics={\n",
    "              \"count\": pl.len(),\n",
    "              \"avg_price\": pl.col(\"close\").mean(),\n",
    "              \"total_volume\": pl.col(\"vol\").sum()\n",
    "          })\n",
    "    .collect()\n",
    "    .sort(\"alpha_bin\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Time for Plotting\n",
    "\n",
    "The `tod_*` column is perfect for time-series plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data ready for plotting:\n",
      "shape: (5, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ ticktime â”† price â”† tod_ticktime â”† elapsed_ticktime â”‚\n",
      "â”‚ ---      â”† ---   â”† ---          â”† ---              â”‚\n",
      "â”‚ i64      â”† f64   â”† time         â”† i64              â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 93000000 â”† 10.5  â”† 09:30:00     â”† 0                â”‚\n",
      "â”‚ 93060000 â”† 10.6  â”† 09:31:00     â”† 60000            â”‚\n",
      "â”‚ 93120000 â”† 10.7  â”† 09:31:20     â”† 80000            â”‚\n",
      "â”‚ 93180000 â”† 10.8  â”† 09:32:20     â”† 140000           â”‚\n",
      "â”‚ 93240000 â”† 10.9  â”† 09:32:40     â”† 160000           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Use tod_ticktime as x-axis in your plots!\n"
     ]
    }
   ],
   "source": [
    "# Example: prepare data for plotting\n",
    "plot_data = (\n",
    "    pl.DataFrame({\n",
    "        \"ticktime\": [93000000 + i*60000 for i in range(120)],  # Every minute for 2 hours\n",
    "        \"price\": [10.50 + 0.1 * (i % 20) for i in range(120)]\n",
    "    }).lazy()\n",
    "    .pipe(vf.parse_time, timestamp_col=\"ticktime\")\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"\\nData ready for plotting:\")\n",
    "print(plot_data.head())\n",
    "print(\"\\nUse tod_ticktime as x-axis in your plots!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n**VizFlow v0.4.0 workflow:**\n\n1. **Configure once**: `vf.set_config(config)` at the top of your notebook\n2. **Load data**: Use Polars `pl.scan_parquet()` for lazy loading\n3. **Parse time**: `vf.parse_time(df)` adds `tod_*` and `elapsed_*` columns\n4. **Bin values**: `vf.bin(df, widths={...})` for discretization\n5. **Aggregate**: `vf.aggregate(df, group_by=[...], metrics={...})`\n6. **Chain operations**: Use `.pipe()` for clean functional workflows\n\n**Key benefits:**\n- âœ… No repetitive parameter passing (config is global)\n- âœ… Works seamlessly with Polars LazyFrame (TB-scale data)\n- âœ… `tod_*` columns ready for plotting (pl.Time type)\n- âœ… `elapsed_*` columns in milliseconds (precise, no float errors)\n- âœ… Functional API - pure functions, easy to test and compose\n\n**Architecture:**\n- **Map-Reduce-Visualize** pattern for TB-scale data\n- **Date-partitioned** execution (~5GB per file, perfect parallelism)\n- **Lazy evaluation** - defer computation until necessary\n- **Two materialization points** - after FIFO, after aggregation\n\n---\n\n## ğŸ“š Documentation\n\n- **[DESIGN.md](https://github.com/ExocortexSebastian/VizFlow/blob/main/docs/DESIGN.md)** - Architecture and pipeline stages\n- **[VERSIONING.md](https://github.com/ExocortexSebastian/VizFlow/blob/main/docs/VERSIONING.md)** - Roadmap and release strategy\n- **[PLAN.md](https://github.com/ExocortexSebastian/VizFlow/blob/main/docs/PLAN.md)** - Implementation plan\n- **[README.md](https://github.com/ExocortexSebastian/VizFlow/blob/main/README.md)** - Quick start guide\n\n---\n\n## ğŸ¯ Next Steps\n\n**For current version (v0.4.0):**\n- Try with your own market data\n- Experiment with custom metrics in `aggregate()`\n- Chain multiple operations with `.pipe()`\n\n**For upcoming features:**\n- â³ **v0.5.0 (FIFO)** - Match buy/sell trades with automatic splitting\n- â³ **v0.6.0 (Returns)** - Calculate forward returns at multiple horizons\n- â³ **v0.7.0 (Execution)** - Scale to multi-day batch processing with `run_batch()` and `run_cluster()`\n\n**Feedback welcome**: [GitHub Issues](https://github.com/ExocortexSebastian/VizFlow/issues)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}